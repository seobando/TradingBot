{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seobando/TradingBot/blob/main/5_model_parameters_searching.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_a8JpJW9qfB",
        "outputId": "51fd8eed-c840-45ad-c622-5947f4851ec3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "## Colab Set up\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uA5zYRtn9ofQ",
        "outputId": "29245ec4-4ee5-46ba-b4ca-338b3c925089"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/1 Formal Training/2 Msc. Ciencia de los datos/Semestre IV/Trader\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/1 Formal Training/2 Msc. Ciencia de los datos/Semestre IV/Trader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NI0IWdVQ1ODg"
      },
      "outputs": [],
      "source": [
        "## Libraries\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from env import environment\n",
        "import time\n",
        "from datetime import datetime\n",
        "from mpl_toolkits import mplot3d\n",
        "from collections import deque\n",
        "from ddpg_agent import Agent\n",
        "import matplotlib.pyplot as plt\n",
        "env = environment()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from google.colab import output\n",
        "import IPython\n",
        "out = display(IPython.display.Pretty('Starting'), display_id=True)\n",
        "time.sleep(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "8YpPg0W33a4z",
        "outputId": "5b1a6628-5f0e-4ef6-a48b-7c1d2392fe07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Starting"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "HJZtn1DjwknJ"
      },
      "outputs": [],
      "source": [
        "## Define Agent\n",
        "def ddpg_agent(experiment,InitialBudget,state_list,df,random_seed,fc1, fc2, fc3, fc4, fc5, fc6, fc7, fc8, fc9, fc10, fc11,learning_period, update_factor,layer_type,minibatch_size):     \n",
        "    \n",
        "    possibilities = {0:\"Hold\",1:\"Buy\",2:\"Sell\"}  \n",
        "    set_size = 3\n",
        "    n_episodes = 1\n",
        "    num_agents = 1\n",
        "    action_size = 3\n",
        "    state_size = len(state_list)\n",
        "    print_every = 1\n",
        "    deque_size = 10\n",
        "    scores_deque = deque(maxlen=deque_size)\n",
        "    duration_deque = deque(maxlen=deque_size)\n",
        "    progress_deque = deque(maxlen=deque_size)\n",
        "    global_score = []\n",
        "    size = len(df.index)\n",
        "    max_t = len(df.index)\n",
        "    reward = 0\n",
        "    average_score = 0\n",
        "    performance = 0\n",
        "    average_duration = 0    \n",
        "\n",
        "    # Initialize agent\n",
        "    agent = Agent(state_size, \n",
        "                action_size, \n",
        "                random_seed,\n",
        "                fc1, fc2, fc3, fc4, fc5, fc6, fc7, fc8, fc9, fc10, fc11,\n",
        "                learning_period, update_factor,\n",
        "                layer_type,\n",
        "                minibatch_size  \n",
        "                )\n",
        "    \n",
        "    # Iterate over episodes\n",
        "    for i_episode in range(1, n_episodes+1):\n",
        "\n",
        "        start_time = time.time()\n",
        "        done = False\n",
        "        Budget = InitialBudget\n",
        "        BuyPrice = 0\n",
        "        scores = np.zeros(num_agents)\n",
        "        t = 0\n",
        "        score = 0\n",
        "        agent.reset()\n",
        "\n",
        "        while True:\n",
        "\n",
        "            price = df[\"Close\"].iloc[t]\n",
        "            date = df[\"Date\"].iloc[t]\n",
        "            state = env.row_values(df,t,state_list,num_agents,state_size)\n",
        "            actions = agent.act(state)\n",
        "            reward,done,action,BuyPrice,Budget = env.step(done,reward,actions,price,BuyPrice,Budget,InitialBudget)      \n",
        "            scores += reward\n",
        "\n",
        "            # Game Pass\n",
        "            if t+1 >= max_t:\n",
        "                break    \n",
        "\n",
        "            # TEST\n",
        "            performance = round(Budget/InitialBudget-1,2)    \n",
        "            #print(\"Action: \", possibilities[action], \"Budget: \", Budget,\"InitialBudget: \", InitialBudget, \"Performance: \", performance)\n",
        "                \n",
        "            # TEST\n",
        "            out.update(IPython.display.Pretty(\"Experiment: {experiment},Episode: {i_episode}, date:  {date}, action: {action}, score: {score}, steps: {steps}, Initial_Budget: {initial_budget}, Budget: {budget}, Performance: {performance}\".format(experiment = experiment, i_episode = i_episode, date = date, action = possibilities[action] , score = round(np.mean(scores),2), steps = t, initial_budget = InitialBudget,budget = round(Budget,2), performance = performance)))\n",
        "            time.sleep(1)\n",
        "\n",
        "            next_state = env.row_values(df,t+1,state_list,num_agents,state_size)    \n",
        "            agent.step(state, actions, reward, next_state, done,t,minibatch_size)  \n",
        "            t+=1\n",
        "\n",
        "            # Game Lose\n",
        "            if done:\n",
        "                break                          \n",
        "\n",
        "        # Score\n",
        "        score = np.mean(scores)\n",
        "        scores_deque.append(score)\n",
        "        average_score = round(np.mean(scores_deque),6)\n",
        "        global_score.append(score)\n",
        "\n",
        "        # Progress\n",
        "        progress = t/max_t\n",
        "        progress_deque.append(progress)\n",
        "        average_progress = round(np.mean(progress_deque),2)\n",
        "\n",
        "        # Performance\n",
        "        performance = round(Budget/InitialBudget-1,2)\n",
        "\n",
        "        # Duration\n",
        "        end_time = time.time()\n",
        "        duration = round(end_time - start_time,2)\n",
        "        duration_deque.append(duration)\n",
        "        average_duration = round(np.mean(duration_deque),2)\n",
        "    \n",
        "    print(\"Experiment: {experiment} ,Episode: {i_episode}, Performance: {performance}, Avg Progress: {average_progress}, Avg Score: {average_score}, Avg Duration: {average_duration}\".format(experiment = experiment, i_episode = i_episode, performance = performance, average_progress = average_progress, average_score = average_score, average_duration = average_duration))\n",
        "\n",
        "    result_list = [experiment,performance,average_progress,average_score,average_duration,]  \n",
        "\n",
        "            \n",
        "    return result_list                  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sVluzMlnwknP"
      },
      "outputs": [],
      "source": [
        "## Load Data\n",
        "experiments = pd.read_csv(\"data/experiments.csv\")\n",
        "number_experiments = len(experiments.index)\n",
        "\n",
        "dataset = \"data/data_daily_interpreted_BTC-USD.csv\"\n",
        "data = pd.read_csv(dataset)\n",
        "df = data[data[\"Date\"]>= \"2020-01-01\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "id": "EqbMCFwjpbza",
        "outputId": "66a1c9f0-6163-42e2-b7e3-75a1dd775ef7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Experiment: 32,Episode: 1, date:  2022-01-03, action: Sell, score: -619.39, steps: 733, Initial_Budget: 687896.25, Budget: 698630.37, Performance: 0.02"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Experiment: 1 ,Episode: 1, Performance: 0.03, Avg Progress: 1.0, Avg Score: -574.00785, Avg Duration: 739.87\n",
            "Experiment: 2 ,Episode: 1, Performance: -0.07, Avg Progress: 1.0, Avg Score: -624.385989, Avg Duration: 737.95\n",
            "Experiment: 3 ,Episode: 1, Performance: -0.05, Avg Progress: 1.0, Avg Score: -604.517462, Avg Duration: 737.8\n",
            "Experiment: 4 ,Episode: 1, Performance: -0.07, Avg Progress: 1.0, Avg Score: -624.385989, Avg Duration: 737.89\n",
            "Experiment: 5 ,Episode: 1, Performance: -0.06, Avg Progress: 1.0, Avg Score: -592.600296, Avg Duration: 737.89\n",
            "Experiment: 6 ,Episode: 1, Performance: -0.05, Avg Progress: 1.0, Avg Score: -604.517462, Avg Duration: 737.83\n",
            "Experiment: 7 ,Episode: 1, Performance: -0.07, Avg Progress: 1.0, Avg Score: -624.385989, Avg Duration: 737.88\n",
            "Experiment: 8 ,Episode: 1, Performance: -0.05, Avg Progress: 1.0, Avg Score: -604.517462, Avg Duration: 737.85\n",
            "Experiment: 9 ,Episode: 1, Performance: -0.06, Avg Progress: 1.0, Avg Score: -582.808293, Avg Duration: 737.85\n",
            "Experiment: 10 ,Episode: 1, Performance: -0.06, Avg Progress: 1.0, Avg Score: -592.600296, Avg Duration: 737.98\n",
            "Experiment: 11 ,Episode: 1, Performance: -0.01, Avg Progress: 1.0, Avg Score: -594.796594, Avg Duration: 738.28\n",
            "Experiment: 12 ,Episode: 1, Performance: -0.06, Avg Progress: 1.0, Avg Score: -582.808293, Avg Duration: 737.82\n",
            "Experiment: 13 ,Episode: 1, Performance: -0.05, Avg Progress: 1.0, Avg Score: -619.392606, Avg Duration: 737.95\n",
            "Experiment: 14 ,Episode: 1, Performance: -0.02, Avg Progress: 1.0, Avg Score: -654.522106, Avg Duration: 738.12\n",
            "Experiment: 15 ,Episode: 1, Performance: -0.05, Avg Progress: 1.0, Avg Score: -619.392606, Avg Duration: 737.94\n",
            "Experiment: 16 ,Episode: 1, Performance: -0.05, Avg Progress: 1.0, Avg Score: -619.392606, Avg Duration: 737.96\n",
            "Experiment: 17 ,Episode: 1, Performance: -0.06, Avg Progress: 1.0, Avg Score: -582.808293, Avg Duration: 737.92\n",
            "Experiment: 18 ,Episode: 1, Performance: -0.05, Avg Progress: 1.0, Avg Score: -604.517462, Avg Duration: 737.87\n",
            "Experiment: 19 ,Episode: 1, Performance: -0.06, Avg Progress: 1.0, Avg Score: -592.600296, Avg Duration: 737.93\n",
            "Experiment: 20 ,Episode: 1, Performance: -0.02, Avg Progress: 1.0, Avg Score: -615.864231, Avg Duration: 738.52\n",
            "Experiment: 21 ,Episode: 1, Performance: -0.06, Avg Progress: 1.0, Avg Score: -582.808293, Avg Duration: 737.91\n",
            "Experiment: 22 ,Episode: 1, Performance: -0.06, Avg Progress: 1.0, Avg Score: -625.933448, Avg Duration: 737.8\n",
            "Experiment: 23 ,Episode: 1, Performance: -0.07, Avg Progress: 1.0, Avg Score: -624.385989, Avg Duration: 737.83\n",
            "Experiment: 24 ,Episode: 1, Performance: -0.06, Avg Progress: 1.0, Avg Score: -625.933448, Avg Duration: 737.78\n",
            "Experiment: 25 ,Episode: 1, Performance: 0.04, Avg Progress: 1.0, Avg Score: -619.006374, Avg Duration: 738.55\n",
            "Experiment: 26 ,Episode: 1, Performance: 0.06, Avg Progress: 1.0, Avg Score: -601.1424, Avg Duration: 740.46\n",
            "Experiment: 27 ,Episode: 1, Performance: -0.06, Avg Progress: 1.0, Avg Score: -625.933448, Avg Duration: 737.81\n",
            "Experiment: 28 ,Episode: 1, Performance: 0.04, Avg Progress: 1.0, Avg Score: -590.494855, Avg Duration: 738.39\n",
            "Experiment: 29 ,Episode: 1, Performance: -0.06, Avg Progress: 1.0, Avg Score: -625.933448, Avg Duration: 737.88\n",
            "Experiment: 30 ,Episode: 1, Performance: -0.03, Avg Progress: 1.0, Avg Score: -607.564281, Avg Duration: 737.99\n",
            "Experiment: 31 ,Episode: 1, Performance: -0.06, Avg Progress: 1.0, Avg Score: -592.600296, Avg Duration: 737.91\n",
            "Experiment: 32 ,Episode: 1, Performance: -0.05, Avg Progress: 1.0, Avg Score: -619.392606, Avg Duration: 737.94\n"
          ]
        }
      ],
      "source": [
        "## Implement Agent\n",
        "kpis = [\"Open_interpreted\",\n",
        "        \"High_interpreted\",\n",
        "        \"Low_interpreted\",\n",
        "        \"MA_short_interpreted\",\n",
        "        \"MA_long_interpreted\",\n",
        "        \"EMA_short_interpreted\",\n",
        "        \"EMA_long_interpreted\",\n",
        "        \"MACD_interpreted\",\n",
        "        \"BIAS_short_interpreted\", \n",
        "        \"BIAS_long_interpreted\", \n",
        "        #\"VR\", \n",
        "        \"OBV_interpreted\"\n",
        "        ]\n",
        "    \n",
        "results_structure = [\"Experiment\",\n",
        "                     \"Performance\",\n",
        "                     \"Avg Progress\",\n",
        "                     \"Avg Score\",\n",
        "                     \"Avg Duration\"\n",
        "                    ]\n",
        "\n",
        "results = pd.DataFrame(columns=results_structure)        \n",
        "# Loop\n",
        "for i in range(number_experiments):\n",
        "\n",
        "    ## Experiment\n",
        "    experiment = experiments[\"Experiments\"].iloc[i]\n",
        "    ## Time Frames\n",
        "\n",
        "    ## KPIS\n",
        "    state_list = kpis\n",
        "    ## Nodes\n",
        "    nodes = int(experiments[\"Nodes\"].iloc[i]) \n",
        "    fc1 = nodes \n",
        "    fc2 = nodes\n",
        "    fc3 = nodes\n",
        "    fc4 = nodes\n",
        "    fc5 = nodes\n",
        "    fc6 = nodes\n",
        "    fc7 = nodes \n",
        "    fc8 = nodes\n",
        "    fc9 = nodes\n",
        "    fc10 = nodes\n",
        "    fc11 = nodes\n",
        "    ## Layers Type\n",
        "    layer_amount_type = experiments[\"Layer Amount Type\"].iloc[i]\n",
        "    ## Layer Type Critic\n",
        "    layer_type = experiments[\"Layers Type\"].iloc[i]\n",
        "                \n",
        "    if layer_type != \"Constant\":\n",
        "        if nodes == int(600):\n",
        "          fc6 = 600\n",
        "          fc7 = 500\n",
        "          fc8 = 400\n",
        "          fc9 = 300\n",
        "          fc10 = 300\n",
        "          fc11 = 300\n",
        "        else:\n",
        "          fc6 = 1024\n",
        "          fc7 = 512\n",
        "          fc8 = 256\n",
        "          fc9 = 128\n",
        "          fc10 = 128\n",
        "          fc11 = 128              \n",
        "    ## Learning Period\n",
        "    learning_period = experiments[\"Learning Period\"].iloc[i]\n",
        "    ## Update Factor \n",
        "    update_factor = experiments[\"Update Factor\"].iloc[i]\n",
        "    ## Random Seed\n",
        "    random_seed = 42\n",
        "    ## Minibatch Size\n",
        "    minibatch_size = experiments[\"Minibatch\"].iloc[i]         \n",
        "    ## Initial Budget\n",
        "    InitialBudget = df[\"High\"].max()*10\n",
        "\n",
        "    #TEST  \n",
        "    test = [\n",
        "            experiment,\n",
        "            nodes ,\n",
        "            fc1 ,\n",
        "            fc2,\n",
        "            fc3,\n",
        "            fc4,\n",
        "            fc5,\n",
        "            fc6,\n",
        "            fc7,\n",
        "            fc8,\n",
        "            fc9,\n",
        "            fc10,\n",
        "            fc11,\n",
        "            layer_amount_type,\n",
        "            layer_type,\n",
        "            learning_period,\n",
        "            update_factor,\n",
        "            random_seed,\n",
        "            minibatch_size,    \n",
        "            InitialBudget\n",
        "          ]\n",
        "\n",
        "    #print(test)      \n",
        "    #print(\"Initial Budget: \", InitialBudget)\n",
        "    try:\n",
        "      result_list = ddpg_agent(experiment,InitialBudget,state_list,df,random_seed,fc1, fc2, fc3, fc4, fc5, fc6, fc7, fc8, fc9, fc10, fc11,learning_period, update_factor,layer_amount_type,minibatch_size)\n",
        "      results = results.append(pd.DataFrame([result_list],columns=results_structure))   \n",
        "      results.to_csv(\"data/results.csv\") \n",
        "    except:\n",
        "      print(\"Not Working :\", experiment, \"Nodes: \", nodes, \"Minibatch size: \", minibatch_size, \"Layer type: \", layer_type) "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "5_model_parameters_searching.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}