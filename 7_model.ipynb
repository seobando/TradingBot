{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seobando/TradingBot/blob/main/7_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_a8JpJW9qfB"
      },
      "outputs": [],
      "source": [
        "## Colab Set up\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uA5zYRtn9ofQ"
      },
      "outputs": [],
      "source": [
        "%cd /content/drive/MyDrive/1 Formal Training/2 Msc. Ciencia de los datos/Semestre IV/Trader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NI0IWdVQ1ODg"
      },
      "outputs": [],
      "source": [
        "## Libraries\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from env import environment\n",
        "import time\n",
        "from datetime import datetime\n",
        "from mpl_toolkits import mplot3d\n",
        "from collections import deque\n",
        "from ddpg_agent import Agent\n",
        "import matplotlib.pyplot as plt\n",
        "env = environment()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8YpPg0W33a4z"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from google.colab import output\n",
        "import IPython\n",
        "out = display(IPython.display.Pretty('Starting'), display_id=True)\n",
        "time.sleep(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJZtn1DjwknJ"
      },
      "outputs": [],
      "source": [
        "## Define Agent\n",
        "def ddpg_agent(experiment,InitialBudget,state_list,df,random_seed,fc1, fc2, fc3, fc4, fc5, fc6, fc7, fc8, fc9, fc10, fc11,learning_period, update_factor,layer_type,minibatch_size):       \n",
        "\n",
        "    possibilities = {0:\"Hold\",1:\"Buy\",2:\"Sell\"} \n",
        "    set_size = 3\n",
        "    n_episodes = 1000\n",
        "    num_agents = 1\n",
        "    action_size = 3\n",
        "    state_size = len(state_list)\n",
        "    print_every = 1\n",
        "    deque_size = 10\n",
        "    scores_deque = deque(maxlen=deque_size)\n",
        "    duration_deque = deque(maxlen=deque_size)\n",
        "    performance_deque = deque(maxlen=deque_size)\n",
        "    global_score = []\n",
        "    size = len(df.index)\n",
        "    max_t = len(df.index)\n",
        "    reward = 0\n",
        "    average_score = 0\n",
        "    average_performance = 0\n",
        "    average_duration = 0  \n",
        "\n",
        "    # Initialize agent\n",
        "    agent = Agent(state_size, \n",
        "                action_size, \n",
        "                random_seed,\n",
        "                fc1, fc2, fc3, fc4, fc5, fc6, fc7, fc8, fc9, fc10, fc11,\n",
        "                learning_period, update_factor,\n",
        "                layer_type,\n",
        "                minibatch_size  \n",
        "                )\n",
        "    \n",
        "    # Iterate over episodes\n",
        "    for i_episode in range(1, n_episodes+1):\n",
        "\n",
        "        start_time = time.time()\n",
        "        done = False\n",
        "        Budget = InitialBudget\n",
        "        BuyPrice = 0\n",
        "        scores = np.zeros(num_agents)\n",
        "        t = 0\n",
        "        score = 0\n",
        "        agent.reset()\n",
        "\n",
        "        while True:\n",
        "\n",
        "            price = df[\"Close\"].iloc[t]\n",
        "            date = df[\"Date\"].iloc[t]\n",
        "            state = env.row_values(df,t,state_list,num_agents,state_size)\n",
        "            actions = agent.act(state)\n",
        "            reward,done,action,BuyPrice,Budget = env.step(done,reward,actions,price,BuyPrice,Budget,InitialBudget)      \n",
        "            scores += reward\n",
        "\n",
        "            # Game Pass\n",
        "            if t+1 >= max_t:\n",
        "                break    \n",
        "\n",
        "            next_state = env.row_values(df,t+1,state_list,num_agents,state_size)    \n",
        "            agent.step(state, actions, reward, next_state, done,t,minibatch_size)  \n",
        "            t+=1\n",
        "\n",
        "            # Game Lose\n",
        "            if done:\n",
        "                break                          \n",
        "\n",
        "            # TEST\n",
        "            performance = round(Budget/InitialBudget-1,6)    \n",
        "            #print(\"Action: \", possibilities[action], \"Budget: \", Budget,\"InitialBudget: \", InitialBudget, \"Performance: \", performance)\n",
        "                \n",
        "            # TEST\n",
        "            out.update(IPython.display.Pretty(\"Experiment: {experiment},Episode: {i_episode}, date:  {date}, action: {action}, score: {score}, steps: {steps}, Initial Budget: {initial_budget} , Budget: {budget}, Performance: {performance}\".format(experiment = experiment, i_episode = i_episode, date = date, action = possibilities[action] , score = round(np.mean(scores),2), steps = t, initial_budget = round(InitialBudget,2), budget = round(Budget,2), performance = performance)))\n",
        "            time.sleep(1)\n",
        "\n",
        "        score = np.mean(scores)\n",
        "        scores_deque.append(score)\n",
        "        average_score = round(np.mean(scores_deque),6)\n",
        "\n",
        "        performance = round(Budget/InitialBudget-1,2)\n",
        "        performance_deque.append(performance)\n",
        "        average_performance = round(np.mean(performance_deque),2)\n",
        "\n",
        "        end_time = time.time()\n",
        "        duration = round(end_time - start_time,2)\n",
        "        duration_deque.append(duration)\n",
        "        average_duration = round(np.mean(duration_deque),2)\n",
        "        global_score.append(score)\n",
        "\n",
        "        # Model valiation\n",
        "        torch.save(agent.actor_local.state_dict(), 'checkpoint_actor.pth')\n",
        "        torch.save(agent.critic_local.state_dict(), 'checkpoint_critic.pth') \n",
        "    \n",
        "        #print(\"Experiment: {experiment} ,Episode: {i_episode}, Avg Performance: {average_performance}, Avg Score: {average_score}, Avg Duration: {average_duration}, Budget: {budget}, Performance: {performance}\".format(experiment = experiment, i_episode = i_episode, average_performance = average_performance, average_score = average_score, average_duration = average_duration, budget = round(Budget,2), performance = performance))        \n",
        "\n",
        "    return global_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sVluzMlnwknP"
      },
      "outputs": [],
      "source": [
        "## Load Data\n",
        "experiments = pd.read_csv(\"data/experiment.csv\").drop(\"Unnamed: 0\",axis=1)\n",
        "number_experiments = 1\n",
        "\n",
        "dataset = \"data/data_daily_interpreted_BTC-USD.csv\"\n",
        "data = pd.read_csv(dataset)\n",
        "df = data[data[\"Date\"]>= \"2020-01-01\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EqbMCFwjpbza"
      },
      "outputs": [],
      "source": [
        "## Implement Agent\n",
        "kpis = [\"Open_interpreted\",\n",
        "        \"High_interpreted\",\n",
        "        \"Low_interpreted\",\n",
        "        \"MA_short_interpreted\",\n",
        "        \"MA_long_interpreted\",\n",
        "        \"EMA_short_interpreted\",\n",
        "        \"EMA_long_interpreted\",\n",
        "        \"MACD_interpreted\",\n",
        "        \"BIAS_short_interpreted\", \n",
        "        \"BIAS_long_interpreted\", \n",
        "        #\"VR\", \n",
        "        \"OBV_interpreted\"\n",
        "        ]\n",
        "    \n",
        "results_structure = [\"Experiment\",\n",
        "                     \"Avg Performance\",\n",
        "                     \"Avg Time\",\n",
        "                     \"Avg Score\"\n",
        "                    ]\n",
        "\n",
        "results = pd.DataFrame(columns=results_structure)        \n",
        "# Loop\n",
        "for i in range(number_experiments):\n",
        "\n",
        "    ## Experiment\n",
        "    experiment = experiments[\"Experiment\"].iloc[i]\n",
        "    ## Start Period\n",
        "\n",
        "    # End Period\n",
        "\n",
        "    ## KPIS\n",
        "    state_list = kpis\n",
        "    ## Nodes\n",
        "    nodes = int(experiments[\"Nodes\"].iloc[i]) \n",
        "    fc1 = nodes \n",
        "    fc2 = nodes\n",
        "    fc3 = nodes\n",
        "    fc4 = nodes\n",
        "    fc5 = nodes\n",
        "    fc6 = nodes\n",
        "    fc7 = nodes \n",
        "    fc8 = nodes\n",
        "    fc9 = nodes\n",
        "    fc10 = nodes\n",
        "    fc11 = nodes\n",
        "    ## Layers Type\n",
        "    layer_amount_type = experiments[\"Layer Amount Type\"].iloc[i]\n",
        "    ## Layer Type Critic\n",
        "    layer_type = experiments[\"Layers Type\"].iloc[i]\n",
        "                \n",
        "    if layer_type != \"Constant\":\n",
        "        if nodes == int(600):\n",
        "          fc6 = 600\n",
        "          fc7 = 500\n",
        "          fc8 = 400\n",
        "          fc9 = 300\n",
        "          fc10 = 300\n",
        "          fc11 = 300\n",
        "        else:\n",
        "          fc6 = 1024\n",
        "          fc7 = 512\n",
        "          fc8 = 256\n",
        "          fc9 = 128\n",
        "          fc10 = 128\n",
        "          fc11 = 128              \n",
        "    ## Learning Period\n",
        "    learning_period = experiments[\"Learning Period\"].iloc[i]\n",
        "    ## Update Factor \n",
        "    update_factor = experiments[\"Update Factor\"].iloc[i]\n",
        "    ## Random Seed\n",
        "    random_seed = 42\n",
        "    ## Minibatch Size\n",
        "    minibatch_size = experiments[\"Minibatch\"].iloc[i]         \n",
        "    ## Initial Budget\n",
        "    InitialBudget = df[\"High\"].max()*10\n",
        "\n",
        "    #TEST  \n",
        "    test = [\n",
        "            experiment,\n",
        "            nodes ,\n",
        "            fc1 ,\n",
        "            fc2,\n",
        "            fc3,\n",
        "            fc4,\n",
        "            fc5,\n",
        "            fc6,\n",
        "            fc7,\n",
        "            fc8,\n",
        "            fc9,\n",
        "            fc10,\n",
        "            fc11,\n",
        "            layer_amount_type,\n",
        "            layer_type,\n",
        "            learning_period,\n",
        "            update_factor,\n",
        "            random_seed,\n",
        "            minibatch_size,    \n",
        "            InitialBudget\n",
        "          ]\n",
        "\n",
        "    #print(test)      \n",
        "    #print(\"Initial Budget: \", InitialBudget)\n",
        "\n",
        "    global_score = ddpg_agent(experiment,InitialBudget,state_list,df,random_seed,fc1, fc2, fc3, fc4, fc5, fc6, fc7, fc8, fc9, fc10, fc11,learning_period, update_factor,layer_amount_type,minibatch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQZ8runkBqHL"
      },
      "outputs": [],
      "source": [
        "## Visualization\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "plt.plot(np.arange(1,len(global_score)+1), global_score)\n",
        "plt.ylabel('Score')\n",
        "plt.xlabel('Episode #')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "7_model.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}